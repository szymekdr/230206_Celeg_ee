---
title: "C.elegans - re-analysis"
author: "Szymek Drobniak"
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 2
    theme: simplex
    embed-resources: true
    code-fold: show
    code-tools: true
    number-sections: true
crossref: 
  fig-title: Figure     # (default is "Figure")
  tbl-title: Table     # (default is "Table")
  title-delim: â€”     # (default is ":")
  fig-prefix: Fig.   # (default is "Figure")
  tbl-prefix: Tab.    # (default is "Table")
editor_options: 
  chunk_output_type: console
---

```{r message = F}
#| output: false
#| warning: false
#| label: packages
#| code-overflow: wrap
#| code-fold: true


library(ggplot2)
library(here)
library(lme4)
library(lmerTest)
library(glmmTMB)
library(car)
library(tidyverse)
library(emmeans)
library(asreml)
library(metafor)
library(gridExtra)
```

## Data wrangling

Restructuring the data to calculate fitness difference (effect size).

First load the data:

```{r}
alldata <- read.table(here("Data", "all.csv"), sep = ";", head = T, stringsAsFactors = T)
ancdata <- read.table(here("Data", "anc.csv"), sep = ";", head = T, stringsAsFactors = T)
```

Summarise the non-ancestral data to have means in each of 4 repeats:

```{r}
alldata_2 <- alldata %>%
  filter(anc_pop != "X") %>%
  group_by(block_unique) %>%
  summarise(mean_Nstart = mean(propN_start),
            mean_N1 = mean(propN_F1),
            SD_Nstart = sd(propN_start),
            SD_N1 = sd(propN_F1),
            population = unique(population),
            isoline = unique(isoline),
            temperature = unique(temperature),
            repr.type = unique(repr.type),
            anc_pop = unique(anc_pop),
            .groups = "drop")
```

Summarise the ancestral data to have means in each of 4 repeats:

```{r}
ancdata_2 <- ancdata %>%
  group_by(block_unique) %>%
  summarise(mean_Nstart_anc = mean(propN_start),
            mean_N1_anc = mean(propN_F1),
            SD_Nstart_anc = sd(propN_start),
            SD_N1_anc = sd(propN_F1))
```

Merge actual data and ancestral data:

```{r}
alldata_2 <- alldata_2 %>%
  left_join(ancdata_2, by = c("anc_pop" = "block_unique")) %>%
  select(-anc_pop)

glimpse(alldata_2)
```

## Effect sizes

We will use two types of fitness measures (for now without explicit errors): proportion difference and (natural log) of proportion ratio.

```{r}
alldata_2 <- alldata_2 %>%
  mutate(fitness_ee_1 = mean_N1 - mean_Nstart,
         fitness_ee_2 = mean_N1/mean_Nstart,
         fitness_ee_3 = log(mean_N1/mean_Nstart),
         
         fitness_anc_1 = mean_N1_anc - mean_Nstart_anc,
         fitness_anc_2 = mean_N1_anc/mean_Nstart_anc,
         fitness_anc_3 = log(mean_N1_anc/mean_Nstart_anc),
         repr.type = relevel(repr.type, ref = "WT"))
```

Let's see the properties of these measures:

```{r}
#| code-fold: true


ggplot(alldata_2) +
  geom_density(mapping = aes(x = fitness_ee_1), colour = "brown") +
  geom_density(mapping = aes(x = fitness_ee_2), colour = "red") +
  geom_density(mapping = aes(x = fitness_ee_3), colour = "orange") +
  theme_classic()

ggplot(alldata_2) +
  geom_density(mapping = aes(x = fitness_anc_1), colour = "darkblue") +
  geom_density(mapping = aes(x = fitness_anc_2), colour = "blue") +
  geom_density(mapping = aes(x = fitness_anc_3), colour = "turquoise") +
  theme_classic()
```

As expected - the `log(proportion_1/proportion_0)` has much better distributional properties.

Let's turn it into a simple effect size (fitness difference, for now without any sampling variance calculation):

```{r}
alldata_2 <- alldata_2 %>%
  mutate(d_1 = fitness_ee_1 - fitness_anc_1,
         d_2 = fitness_ee_2 - fitness_anc_2,
         d_3 = fitness_ee_3 - fitness_anc_3)
```

## Analysis using `lmer()`

```{r}
model1 <- lmer(d_1 ~ isoline * temperature * repr.type + (1|population), data = alldata_2)
model2 <- lmer(d_2 ~ isoline * temperature * repr.type + (1|population), data = alldata_2)
model3 <- lmer(d_3 ~ isoline * temperature * repr.type + (1|population), data = alldata_2)

summary(model1)
summary(model2)
summary(model3)
```

```{r}
emmip(model3, ~temperature+repr.type|isoline, CIs = T,
      CIarg = list(col = "blue")) +
  theme_bw()

emmip(model3, ~temperature+repr.type, CIs = T,
      CIarg = list(col = "blue")) +
  theme_bw()
```

The patterns largely agree with what we can see in the model.

## Sampling variances and meta-analysis

The sampling variances of subsequent effect sizes are based on several relationships. The sampling variances of raw proportions are (because we do not have $N$ for all cases - we will have to make some assumptions, probably not too bold anyways)

$$ var(p)=\frac{p(1-p)}{N}, $$

and variance of the average of 4 proportions is (from stats theory)

$$var(\hat{p}) = \frac{\sum_{i} var(p_{i})}{n^{2}} = \frac{1}{16}\sum_{i} var(p_{i}).$$
Variance of a difference of two proportions $W_{1}=\hat{p}_{2}-\hat{p}_{1}$ is (from the delta method) $var(W_{1})=var(\hat{p}_{2})+var(\hat{p}_{1})$. We are ignoring here covariance of two proportions (which is reasonable, they should not covary in general 'casue are the result of (unpredictable) competition) - but above we also ignored covariance of 4 replicated proportion which may not be reasonable, in such case we would have to increase the estimate (maybe worth trying) assuming some correlation $r$:

$$var(\hat{p}) = \frac{\sum_{i} var(p_{i}) + 2\sum_{i}\sum_{j<1}cov(p_{i}p_{j})}{n^{2}} = \\ \frac{1}{16}\sum_{i} var(p_{i})+2\sum_{i}\sum_{j>i}r \sqrt{var(p_{i})}\sqrt{var(p_{j})}.$$
This correction can be seen as an alternative to correcting for multiple comparisons (and it actually achieves what we need - decreases Type I error in zero-ES cases to roughly 5%).

Sampling variance of a log ratio is (from delta method):

$$var(W_{2}) = var[ln(\frac{\hat{p_{2}}}{\hat{p_{1}}})] = \\ 
[\frac{\partial}{\partial \hat{p_{2}}}(ln\:\hat{p_{2}}-ln\:\hat{p_{1}})]^{2}\:var(p_{2}) + \\
[\frac{\partial}{\partial \hat{p_{1}}}(ln\:\hat{p}_{2}-ln\:\hat{p}_{1})]^{2}\:var(\hat{p}_{1}) = \\ \frac{1}{\hat{p_{2}}^{2}}\:var(\hat{p_{2}})+\frac{1}{\hat{p_{1}}^{2}}\:var(\hat{p_{1}}).$$

And finally - using those variances and fitness estimates - we can calculate $d$ and it's sampling variance (in the usual way):

$$d = \frac {{W_{x,ee}} - {W_{x,anc}}} {s_{pooled}}J,$$
$$s_{pooled} = \sqrt{\frac{(n_{1}-1)\:var(W_{x,ee})+(n_{2}-1)\:var(W_{x,anc})}{n_{ee}+n_{anc}-2}},$$

$$J = 1-\frac{3}{4(n_{ee}+n_{anc}-2)-1}.$$

First - let's calculate relevant effect sizes and sampling variances. We need to repeat the above calculations adding proportion sampling variance to original data:

```{r}
correction <- 2*3*0.8*0.0005
# this correction assumes that on average variance of proportion estimation here is 0.0005
# (close to actual averages of 0.0003-0.0006) and that (due to coming from the same
# realisation of breeding the 4 replicates are strongly correlated (r = 0.8)
# number 3 comes from the fact that in a 4x4 covariance matrix there are 3 correlations

alldata_2 <- alldata %>%
  filter(anc_pop != "X") %>%
  mutate(varNstart = (propN_start*(1-propN_start))/sum,
         varN1 = (propN_F1*(1-propN_F1))/(sum)) %>%
  group_by(block_unique) %>%
  summarise(mean_Nstart = mean(propN_start),
            mean_N1 = mean(propN_F1),
            var_Nstart = (sum(varNstart)/16)+correction,
            var_N1 = (sum(varN1)/16)+correction,
            population = unique(population),
            isoline = unique(isoline),
            temperature = unique(temperature),
            repr.type = unique(repr.type),
            anc_pop = unique(anc_pop),
            .groups = "drop")
```


```{r}
ancdata_2 <- ancdata %>%
  mutate(varNstart = (propN_start*(1-propN_start))/sum,
         varN1 = (propN_F1*(1-propN_F1))/(sum)) %>%
  group_by(block_unique) %>%
  summarise(mean_Nstart_anc = mean(propN_start),
            mean_N1_anc = mean(propN_F1),
            var_Nstart_anc = (sum(varNstart)/16)+correction,
            var_N1_anc = (sum(varN1)/16)+correction)
```

Merge actual data and ancestral data:

```{r}
alldata_2 <- alldata_2 %>%
  left_join(ancdata_2, by = c("anc_pop" = "block_unique")) %>%
  select(-anc_pop)

glimpse(alldata_2)
```

```{r}
alldata_2 <- alldata_2 %>%
  mutate(fitness_ee_1 = mean_N1 - mean_Nstart,
         fitness_ee_2 = log(mean_N1/mean_Nstart),
         var_f_ee_1 = var_Nstart + var_N1,
         var_f_ee_2 = (1/mean_N1^2)*var_N1 + (1/mean_Nstart^2)*var_Nstart,
         
         fitness_anc_1 = mean_N1_anc - mean_Nstart_anc,
         fitness_anc_2 = log(mean_N1_anc/mean_Nstart_anc),
         var_f_anc_1 = var_Nstart_anc + var_N1_anc,
         var_f_anc_2 = (1/mean_N1_anc^2)*var_N1_anc + (1/mean_Nstart_anc^2)*var_Nstart_anc,
         repr.type = relevel(repr.type, ref = "WT"))
```

Finally let's calculate Hedge's $g$:

```{r}
J <- 1 - (3/(4*(4+4-2) - 1))
alldata_2 <- alldata_2 %>%
  mutate(d_1 = J*(fitness_ee_1 - fitness_anc_1)/sqrt((3*var_f_ee_1 + 3*var_f_anc_1)/(4+4-2)),
         d_2 = J*(fitness_ee_2 - fitness_anc_2)/sqrt((3*var_f_ee_2 + 3*var_f_anc_2)/(4+4-2)),
         
         var_d_1 = (8/16)+(d_1^2/16),
         var_d_2 = (8/16)+(d_2^2/16))
```

## Meta-analysis

```{r}
alldata_2 <- mutate(alldata_2, weight_1 = 1/var_d_1, weight_2 = 1/var_d_2)
alldata_2$esid <- as.factor(1:nrow(alldata_2))
# ES = difference in proportions
model1 <- rma.mv(d_1 ~ isoline * temperature * repr.type,
                 random = list(~ 1|population,
                               ~ 1|esid),
                 data = alldata_2,
                 V = var_d_1)
summary(model1)


model2 <- rma.mv(d_2 ~ isoline * temperature * repr.type,
                 random = list(~ 1|population,
                               ~ 1|esid),
                 data = alldata_2,
                 V = var_d_2)
summary(model2)
```

Forest plot of all effect sizes

```{r}
#| code-fold: true


alldata_2$repro.temp <- interaction(alldata_2$repr.type, alldata_2$temperature)
densscale <- 0.025
iso_labs <- c("Line 6", "Line 8", "Line 9")
names(iso_labs) <- c("Iz6", "Iz8", "Iz9")
ggplot(data = arrange(alldata_2, d_2)) +
  geom_density(aes(x = d_2, y = (..count..)*densscale*nrow(alldata_2)),
               colour = "gray", fill = "gray95", trim = F) +
  geom_vline(xintercept = 0, col = 'gray50', lty = 2) +
  geom_point(size = 0.5, aes(x = d_2, y = 1:nrow(alldata_2),
       colour = repro.temp)) +
  geom_errorbarh(aes(y = 1:nrow(alldata_2),
                     xmin = d_2-1.96*sqrt(var_d_2), xmax = d_2+1.96*sqrt(var_d_2),
                     colour = repro.temp)) +
  theme_classic() +
  scale_colour_manual(values = c("blue3", "purple3", "magenta", "firebrick1")) +
  labs(x = 'Cohen\'s d', y = 'Replicate ID', ) +
  facet_grid(~ isoline,
             labeller = labeller(isoline = iso_labs)) +
  theme(strip.background = element_rect(fill = "oldlace", linewidth = 0), text = element_text(size = 15))
```

Divided by populations

```{r}
#| code-fold: true


densscale <- 0.025
iso_labs <- c("Line 6", "Line 8", "Line 9")
names(iso_labs) <- c("Iz6", "Iz8", "Iz9")

# create mock variables to form a good grid (6 x 6 populations)
pops <- levels(alldata_2$population)[-(1:6)]
mockids <- as.data.frame(cbind(
    pops,
    rep(1:6, times = 6),
    rep(1:6, each = 6)
)[1:length(pops), ])
alldata_2 <- alldata_2 %>%
    left_join(mockids, by = c("population" = "pops")) %>%
    arrange(isoline, repr.type, temperature)

# plots <- list()
# i <- 1
# for (popul in alldata_2$population) {
#     alldata_plot <- arrange(filter(alldata_2, population == popul), d_2)
#     alldata_plot$ys <- 1:nrow(alldata_plot)
#     cat(alldata_plot$ys)
#     cat("\n")
#     plots[[i]] <- ggplot(data = alldata_plot) +
#         # geom_density(aes(x = d_2, y = (..count..)*densscale*nrow(alldata_2)),
#         #              colour = "gray", fill = "gray95", trim = F) +
#         geom_vline(xintercept = 0, col = "gray50", lty = 2) +
#         geom_point(size = 0.5, aes(
#             x = d_2, y = ys
#         )) +
#         geom_errorbarh(aes(
#             y = ys,
#             xmin = d_2 - 1.96 * sqrt(var_d_2), xmax = d_2 + 1.96 * sqrt(var_d_2)
#         )) +
#         geom_text(label = popul, x = -3, y = 4.25, size = 20, colour = "gray") +
#         theme_classic() +
#         # scale_colour_manual(values = c("blue3", "purple3", "magenta", "firebrick1")) +
#         labs(x = "Cohen's d", y = "Replicate", ) +
#         # facet_grid(V2 ~ V3) +
#         xlim(min(alldata_2$d_2 - 2 * sqrt(alldata_2$var_d_2)), max(alldata_2$d_2 + 2 * sqrt(alldata_2$var_d_2))) +
#         ylim(0.5, 4.5) +
#         theme(
#             strip.background = element_blank(),
#             strip.text = element_blank(),
#             panel.background = element_rect(fill = "gray98"),
#             text = element_text(size = 15)
#         )
#     names(plots)[i] <- popul
#     i <- i + 1
# }
# nCol <- ceiling(sqrt(length(plots)))
# grid.arrange(grobs = plots, ncol = nCol)

alldata_2 <- alldata_2 %>%
    group_by(population) %>%
    mutate(ys = 1:n())
alldata_2 %>%
    ggplot() +
    geom_text(aes(label = population), x = 3, y = 4.25, size = 5, colour = "gray", hjust = 0, vjust = 1) +
    geom_vline(xintercept = 0, col = "gray50", lty = 2) +
    geom_point(size = 0.9, aes(
        x = d_2, y = ys
    )) +
    geom_errorbarh(aes(
        y = ys,
        xmin = d_2 - 1.96 * sqrt(var_d_2), xmax = d_2 + 1.96 * sqrt(var_d_2)
    ), height = 0.35) +
    theme_classic() +
    # scale_colour_manual(values = c("blue3", "purple3", "magenta", "firebrick1")) +
    labs(x = "Cohen's d", y = "Replicate", ) +
    facet_grid(V2 ~ V3) +
    xlim(min(alldata_2$d_2 - 2 * sqrt(alldata_2$var_d_2)), max(alldata_2$d_2 + 2 * sqrt(alldata_2$var_d_2))) +
    ylim(0.5, 4.5) +
    theme(
        strip.background = element_blank(),
        strip.text = element_blank(),
        panel.background = element_rect(fill = "gray98"),
        text = element_text(size = 15)
    )

```


Predictions from `metafor` model.

```{r}
#| code-fold: true


predictions <- predict(model2, newmods = rbind(
  # i8 i9   t24   rFOG  it it   ir ir   tr    itr itr
  c(0, 0,   0,    0,    0, 0,   0, 0,   0,    0, 0), #iz6 t20 rOUT
  c(1, 0,   0,    0,    0, 0,   0, 0,   0,    0, 0), #iz8 t20 rOUT
  c(0, 1,   0,    0,    0, 0,   0, 0,   0,    0, 0), #iz9 t20 rOUT
  c(0, 0,   1,    0,    0, 0,   0, 0,   0,    0, 0), #iz6 t24 rOUT
  c(0, 0,   0,    1,    0, 0,   0, 0,   0,    0, 0), #iz6 t20 rFOG
  c(1, 0,   1,    0,    1, 0,   0, 0,   0,    0, 0), #iz8 t24 rOUT
  c(0, 1,   1,    0,    0, 1,   0, 0,   0,    0, 0), #iz9 t24 rOUT
  c(1, 0,   0,    1,    0, 0,   1, 0,   0,    0, 0), #iz8 t20 rFOG
  c(0, 1,   0,    1,    0, 0,   0, 1,   0,    0, 0), #iz9 t20 rFOG
  c(0, 0,   1,    1,    0, 0,   0, 0,   1,    0, 0), #iz6 t24 rFOG
  c(1, 0,   1,    1,    1, 0,   1, 0,   1,    1, 0), #iz8 t24 rFOG
  c(0, 1,   1,    1,    0, 1,   0, 1,   1,    0, 1)  #iz9 t24 rFOG
))

predictions <- as.data.frame(predictions)
predictions$izo <- c("i6", "i8", "i9", "i6", "i6", "i8", "i9", "i8", "i9", "i6", "i8", "i9")
predictions$temp <- c("t20", "t20", "t20", "t24", "t20", "t24", "t24", "t20", "t20", "t24", "t24", "t24")
predictions$repro <- c("wt", "wt", "wt", "wt", "fog", "wt", "wt", "fog", "fog", "fog", "fog", "fog")
predictions$temprepr <- paste0(predictions$temp, " x ", predictions$repro)

iso_labs <- c("Line 6", "Line 8", "Line 9")
names(iso_labs) <- c("i6", "i8", "i9")
ggplot(
    data = as.data.frame(predictions),
    mapping = aes(x = temprepr, y = pred)
) +
    geom_line(aes(group = izo)) +
    geom_errorbar(aes(ymin = ci.lb, ymax = ci.ub), colour = "blue", width = 0.25) +
    geom_point(size = 2) +
    scale_x_discrete(limits = c("t20 x wt", "t24 x wt", "t20 x fog", "t24 x fog")) +
    facet_wrap(~izo, scales = "free_x", labeller = labeller(izo = iso_labs)) +
    theme_classic() +
    theme(
        text = element_text(size = 15),
        axis.text.x = element_text(angle = 45, hjust = 1),
        strip.background = element_rect(fill = "oldlace", linewidth = 0)
    ) +
    labs(x = "Temperature x Reproduction type", y = "Predicted effect size")


# emmip(model3, ~temperature+repr.type, CIs = T,
#       CIarg = list(col = "blue")) +
#   theme_bw()
```